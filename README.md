# DataOps Olympics - GSK India x Databricks

Welcome to the **DataOps Olympics** ‚Äî a hands-on, competitive event designed to showcase the power of the Databricks Lakehouse Platform through real-world data engineering and machine learning challenges.

## Prerequisites

- **Databricks Free Edition** workspace (sign up at [databricks.com/try](https://www.databricks.com/try-databricks))
- A running compute cluster (single-node is sufficient)
- Basic familiarity with Python, SQL, and Spark

> **All data used in this event is open-source and publicly available. No proprietary or sensitive data is required.**

---

## Event Overview

| Event | Name | Duration | Focus Area |
|-------|------|----------|------------|
| 1 | **Speed Sprint** | 15 min | End-to-end pipeline (ingest ‚Üí govern ‚Üí query ‚Üí visualize) |
| 2 | **Accuracy Challenge** | 20 min | Predictive modeling (patient readmission risk) |
| 3 | **Innovation Showcase** | 30 min | AI Agent / LLM-powered application |
| 4 | **The Relay Challenge** | 30 min | Multi-stage team relay pipeline |
| 5 | **Plot Twist Finals** | 20 min | Adapt to surprise constraints |

---

## Team Structure

- **8‚Äì10 teams** of 4‚Äì5 people each
- Cross-functional: mix of data scientists, analysts, engineers
- Each team gets a workstation with a pre-configured Databricks workspace

---

## Repository Structure

```
gsk-dataops-olympics/
‚îú‚îÄ‚îÄ README.md                          ‚Üê You are here
‚îú‚îÄ‚îÄ setup/
‚îÇ   ‚îî‚îÄ‚îÄ 00_setup_and_data.py           ‚Üê Run FIRST: downloads data, verifies environment
‚îÇ
‚îú‚îÄ‚îÄ event1_speed_sprint/
‚îÇ   ‚îú‚îÄ‚îÄ starter_notebook.py            ‚Üê Participant notebook (with TODOs)
‚îÇ   ‚îî‚îÄ‚îÄ solution_notebook.py           ‚Üê Reference solution (organizers only)
‚îÇ
‚îú‚îÄ‚îÄ event2_accuracy_challenge/
‚îÇ   ‚îú‚îÄ‚îÄ starter_notebook.py            ‚Üê Participant notebook (with TODOs)
‚îÇ   ‚îî‚îÄ‚îÄ solution_notebook.py           ‚Üê Reference solution (organizers only)
‚îÇ
‚îú‚îÄ‚îÄ event3_innovation_showcase/
‚îÇ   ‚îú‚îÄ‚îÄ starter_notebook.py            ‚Üê Participant notebook (with TODOs)
‚îÇ   ‚îî‚îÄ‚îÄ solution_notebook.py           ‚Üê Reference solution (organizers only)
‚îÇ
‚îú‚îÄ‚îÄ event4_relay_challenge/
‚îÇ   ‚îú‚îÄ‚îÄ leg1_ingestion.py              ‚Üê Person A: Data ingestion & cleansing
‚îÇ   ‚îú‚îÄ‚îÄ leg2_feature_engineering.py    ‚Üê Person B: Feature engineering
‚îÇ   ‚îú‚îÄ‚îÄ leg3_model_training.py         ‚Üê Person C: Model training & MLflow
‚îÇ   ‚îî‚îÄ‚îÄ leg4_deployment.py             ‚Üê Person D: Deployment & dashboarding
‚îÇ
‚îú‚îÄ‚îÄ event5_plot_twist/
‚îÇ   ‚îú‚îÄ‚îÄ base_notebook.py               ‚Üê Working solution to be adapted
‚îÇ   ‚îî‚îÄ‚îÄ twist_cards.py                 ‚Üê Random challenge card generator
‚îÇ
‚îî‚îÄ‚îÄ scoring/
    ‚îî‚îÄ‚îÄ scoreboard.py                  ‚Üê Live scoreboard notebook
```

---

## Quick Start

### Step 1: Import into Databricks
1. In your Databricks workspace, go to **Workspace ‚Üí Import**
2. Import this entire repository (via Git URL or upload as `.dbc`)
3. Or import individual `.py` files as notebooks

### Step 2: Run Setup
1. Open `setup/00_setup_and_data.py`
2. Attach to your compute cluster
3. Run all cells ‚Äî this downloads all open-source datasets and creates the database

### Step 3: Distribute Starter Notebooks
- Give each team the **starter notebooks** for each event
- Keep **solution notebooks** for organizers/judges only

---

## Datasets Used (All Open Source)

| Dataset | Source | Used In |
|---------|--------|---------|
| Heart Disease UCI | [UCI ML Repository](https://archive.ics.uci.edu/dataset/45/heart+disease) | Events 1, 4, 5 |
| Diabetes (Pima Indians) | [Kaggle / UCI](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database) | Event 2 |
| Drug Review Dataset | [UCI ML Repository](https://archive.ics.uci.edu/dataset/462/drug+review+dataset+drugs+com) | Event 3 |
| WHO Life Expectancy | [Kaggle](https://www.kaggle.com/datasets/kumarajarshi/life-expectancy-who) | Event 4 |
| Synthetic Clinical Notes | Generated in setup | Event 3 |

> All datasets are downloaded programmatically during setup. No manual download needed.

---

## Scoring Summary

### Event 1: Speed Sprint (15 min)
| Place | Points |
|-------|--------|
| 1st | 10 |
| 2nd | 8 |
| 3rd | 6 |
| 4th | 5 |
| 5th | 4 |
| 6th+ | 2 |

### Event 2: Accuracy Challenge (20 min)
- **F1 Score** (max 15 pts): Proportional to best score
- **Explainability Bonus** (max 5 pts): Judge-rated
- **Total**: max 20 pts

### Event 3: Innovation Showcase (30 min)
- **Creativity** (max 10 pts)
- **Functionality** (max 10 pts)
- **Usefulness** (max 5 pts)
- **Live Demo Quality** (max 5 pts)
- **Total**: max 30 pts

### Event 4: The Relay Challenge (30 min)
- **Completion Time** (max 15 pts): Inversely proportional
- **Quality Gates** (max 10 pts): Automated checks
- **Penalty**: 2 minutes added per failed checkpoint
- **Total**: max 25 pts

### Event 5: Plot Twist Finals (20 min)
- **Top 3 teams only** (from cumulative scores)
- **Adaptation Speed** (max 10 pts)
- **Solution Quality** (max 10 pts)
- **Presentation** (max 5 pts)
- **Total**: max 25 pts

### Grand Total: max 130 pts

---

## Databricks Free Edition Compatibility

All notebooks are designed to run on **Databricks Free Edition** with these considerations:

| Feature | Free Edition | Notebook Approach |
|---------|-------------|-------------------|
| Delta Lake | ‚úÖ Available | Used throughout |
| Unity Catalog | ‚úÖ Available | Used for governance |
| MLflow | ‚úÖ Available | Used for experiment tracking |
| Spark SQL | ‚úÖ Available | Primary query engine |
| pandas / sklearn | ‚úÖ Available | Used for ML |
| Databricks AI Functions | ‚ö†Ô∏è Limited | Fallback to open-source LLMs |
| Vector Search | ‚ö†Ô∏è Limited | ChromaDB fallback included |
| Model Serving | ‚ö†Ô∏è Limited | Local inference fallback |
| Genie Dashboard | ‚ö†Ô∏è May not be available | Matplotlib/Plotly fallback |

> Notebooks include conditional logic to detect available features and gracefully fall back to alternatives.

---

## For Organizers

### Pre-Event Checklist
- [ ] Create Databricks Free Edition workspaces (1 per team)
- [ ] Run `setup/00_setup_and_data.py` on each workspace
- [ ] Verify all datasets downloaded successfully
- [ ] Import starter notebooks into each workspace
- [ ] Set up `scoring/scoreboard.py` on organizer workspace
- [ ] Print twist cards for Event 5 (in `event5_plot_twist/twist_cards.py`)
- [ ] Assign judges for Events 3 and 5
- [ ] Prepare timers (15 min, 20 min, 30 min)

### Tips
- Have a "help desk" for teams that get stuck on environment issues
- Project the scoreboard on a big screen
- Take photos/videos for internal comms
- Award bonus points for team spirit and collaboration

---

## License

This project uses open-source datasets and is intended for educational and demonstration purposes only. All datasets retain their original licenses. See individual dataset sources for details.

---

**Happy competing! May the best data team win! üèÜ**

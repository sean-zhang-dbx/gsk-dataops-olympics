# Databricks notebook source
# MAGIC %md
# MAGIC # üéØ Event 2: Accuracy Challenge ‚Äî SOLUTION
# MAGIC
# MAGIC > **‚ö†Ô∏è ORGANIZERS ONLY ‚Äî Do not distribute to participants!**

# COMMAND ----------

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import f1_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
import mlflow
import mlflow.sklearn
import plotly.express as px
import plotly.graph_objects as go

# COMMAND ----------

# MAGIC %md
# MAGIC ## Load and Explore

# COMMAND ----------

df = spark.table("diabetes_readmission").toPandas()
print(f"Shape: {df.shape}")
print(f"\nDescribe:\n{df.describe()}")
print(f"\nTarget distribution:\n{df['readmission_risk'].value_counts(normalize=True)}")
print(f"\nCorrelations with target:\n{df.corr()['readmission_risk'].sort_values(ascending=False)}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Feature Engineering

# COMMAND ----------

# Create interaction and derived features
df["glucose_bmi"] = df["glucose"] * df["bmi"]
df["age_glucose"] = df["age"] * df["glucose"]
df["insulin_glucose_ratio"] = df["insulin"] / (df["glucose"] + 1)
df["bmi_age"] = df["bmi"] * df["age"]
df["high_glucose"] = (df["glucose"] > 140).astype(int)
df["obese"] = (df["bmi"] > 30).astype(int)
df["senior"] = (df["age"] > 50).astype(int)
df["high_risk_combo"] = ((df["glucose"] > 140) & (df["bmi"] > 30) & (df["age"] > 45)).astype(int)
df["bp_bmi_ratio"] = df["blood_pressure"] / (df["bmi"] + 1)

print("‚úÖ Features engineered")
print(f"Total features: {df.shape[1] - 1}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Train/Test Split

# COMMAND ----------

feature_cols = [
    "pregnancies", "glucose", "blood_pressure", "skin_thickness",
    "insulin", "bmi", "diabetes_pedigree", "age",
    # Engineered features
    "glucose_bmi", "age_glucose", "insulin_glucose_ratio", "bmi_age",
    "high_glucose", "obese", "senior", "high_risk_combo", "bp_bmi_ratio"
]

X = df[feature_cols]
y = df["readmission_risk"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Training: {X_train.shape}, Test: {X_test.shape}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Model Training

# COMMAND ----------

TEAM_NAME = "solution"
mlflow.set_experiment(f"/dataops_olympics/{TEAM_NAME}_accuracy_challenge")

with mlflow.start_run(run_name="solution_ensemble"):
    
    # Ensemble of GBM + RF
    gb = GradientBoostingClassifier(
        n_estimators=200, max_depth=5, learning_rate=0.1,
        subsample=0.8, random_state=42
    )
    rf = RandomForestClassifier(
        n_estimators=200, max_depth=10, random_state=42
    )
    
    model = VotingClassifier(
        estimators=[("gb", gb), ("rf", rf)],
        voting="soft"
    )
    
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    
    f1 = f1_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_pred_proba)
    
    # Cross-validation
    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring="f1")
    
    mlflow.log_params({
        "model_type": "VotingClassifier(GBM+RF)",
        "gb_n_estimators": 200,
        "gb_max_depth": 5,
        "gb_learning_rate": 0.1,
        "rf_n_estimators": 200,
        "rf_max_depth": 10,
        "n_features": len(feature_cols),
        "engineered_features": True
    })
    
    mlflow.log_metric("f1_score", f1)
    mlflow.log_metric("auc_roc", auc)
    mlflow.log_metric("cv_f1_mean", cv_scores.mean())
    mlflow.log_metric("cv_f1_std", cv_scores.std())
    
    mlflow.sklearn.log_model(model, "model")
    
    print(f"F1 Score: {f1:.4f}")
    print(f"AUC-ROC: {auc:.4f}")
    print(f"CV F1:    {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}")
    print(f"\n{classification_report(y_test, y_pred)}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Explainability

# COMMAND ----------

# Feature Importance (from the RF sub-model)
rf_fitted = model.named_estimators_["rf"]
importances = rf_fitted.feature_importances_
indices = np.argsort(importances)[::-1]

fig = px.bar(
    x=[feature_cols[i] for i in indices],
    y=importances[indices],
    title="Feature Importance (Random Forest)",
    labels={"x": "Feature", "y": "Importance"},
)
fig.update_layout(template="plotly_white", xaxis_tickangle=-45)
fig.show()

# COMMAND ----------

# ROC Curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)

fig_roc = go.Figure()
fig_roc.add_trace(go.Scatter(x=fpr, y=tpr, mode="lines", name=f"Model (AUC={auc:.3f})"))
fig_roc.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode="lines", name="Random", line=dict(dash="dash")))
fig_roc.update_layout(
    title="ROC Curve",
    xaxis_title="False Positive Rate",
    yaxis_title="True Positive Rate",
    template="plotly_white"
)
fig_roc.show()

# COMMAND ----------

# SHAP Values (if available)
try:
    import shap
    
    # Use TreeExplainer on the RF component
    explainer = shap.TreeExplainer(rf_fitted)
    shap_values = explainer.shap_values(X_test)
    
    # Summary plot
    shap.summary_plot(shap_values[1], X_test, feature_names=feature_cols, show=True)
except ImportError:
    print("‚ö†Ô∏è SHAP not installed. Install with: %pip install shap")
    print("   Skipping SHAP analysis.")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Model Documentation
# MAGIC
# MAGIC ### Approach
# MAGIC - **Model**: Soft-voting ensemble of Gradient Boosting + Random Forest
# MAGIC - **Feature Engineering**: Created 9 additional features including interactions, ratios, and binary indicators
# MAGIC - **Key Features**: `glucose`, `bmi`, `age`, and their interactions drove predictions
# MAGIC
# MAGIC ### What Worked
# MAGIC - Feature engineering (interaction terms) boosted F1 by ~0.05
# MAGIC - Ensemble approach was more stable than individual models
# MAGIC - Cross-validation confirmed generalization
# MAGIC
# MAGIC ### What Didn't Work
# MAGIC - Simple logistic regression underfitted
# MAGIC - Too many polynomial features caused overfitting
# MAGIC
# MAGIC ### With More Time
# MAGIC - Hyperparameter tuning with Optuna/Hyperopt
# MAGIC - Try XGBoost/LightGBM
# MAGIC - More sophisticated feature selection (e.g., Boruta)
# MAGIC - Explore Spark ML for distributed training

# COMMAND ----------

print("=" * 60)
print(f"SOLUTION F1 Score: {f1:.4f}")
print(f"SOLUTION AUC-ROC:  {auc:.4f}")
print("=" * 60)
